{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin executing function...\n",
      "a\n",
      "Finished executing function...\n",
      "Time to execute function (milliseconds): 0.0057220458984375\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def stopwatch(func, *args, **kwargs):\n",
    "    print(\"Begin executing function...\")\n",
    "    start = time.time()\n",
    "    funcReturn = func(*args, **kwargs)\n",
    "    stop = time.time()\n",
    "    print('Finished executing function...')\n",
    "    duration = (stop-start)*1000\n",
    "    print(f'Time to execute function (milliseconds): {duration}')\n",
    "    return funcReturn\n",
    "\n",
    "def test(a):\n",
    "    print(a)\n",
    "\n",
    "\n",
    "stopwatch(test, 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data from  data/raw_training/training_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading from .txt files in data/raw_training/training_data/: 100%|██████████| 942/942 [00:00<00:00, 14503.73it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        white-space: pre;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        line-height: 95%;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-top: 0;\n",
       "    }\n",
       "\n",
       "    .dataframe td {\n",
       "        padding-bottom: 0;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\" >\n",
       "<small>shape: (5, 28)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "patient_id\n",
       "</th>\n",
       "<th>\n",
       "murmur_in_patient\n",
       "</th>\n",
       "<th>\n",
       "audio_file\n",
       "</th>\n",
       "<th>\n",
       "annotation_file\n",
       "</th>\n",
       "<th>\n",
       "murmur_in_recording\n",
       "</th>\n",
       "<th>\n",
       "recording_location\n",
       "</th>\n",
       "<th>\n",
       "sampling_frequency\n",
       "</th>\n",
       "<th>\n",
       "total_locations\n",
       "</th>\n",
       "<th>\n",
       "murmur_locations\n",
       "</th>\n",
       "<th>\n",
       "most_audible_location\n",
       "</th>\n",
       "<th>\n",
       "outcome\n",
       "</th>\n",
       "<th>\n",
       "age\n",
       "</th>\n",
       "<th>\n",
       "sex\n",
       "</th>\n",
       "<th>\n",
       "height\n",
       "</th>\n",
       "<th>\n",
       "weight\n",
       "</th>\n",
       "<th>\n",
       "pregnancy_status\n",
       "</th>\n",
       "<th>\n",
       "sys_mur_timing\n",
       "</th>\n",
       "<th>\n",
       "sys_mur_shape\n",
       "</th>\n",
       "<th>\n",
       "sys_mur_pitch\n",
       "</th>\n",
       "<th>\n",
       "sys_mur_grading\n",
       "</th>\n",
       "<th>\n",
       "sys_mur_quality\n",
       "</th>\n",
       "<th>\n",
       "dia_mur_timing\n",
       "</th>\n",
       "<th>\n",
       "dia_mur_shape\n",
       "</th>\n",
       "<th>\n",
       "dia_mur_pitch\n",
       "</th>\n",
       "<th>\n",
       "dia_mur_grading\n",
       "</th>\n",
       "<th>\n",
       "dia_mur_quality\n",
       "</th>\n",
       "<th>\n",
       "campaign\n",
       "</th>\n",
       "<th>\n",
       "additional_id\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "i64\n",
       "</td>\n",
       "<td>\n",
       "list[str]\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "13918\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_AV.wav\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_AV.tsv\"\n",
       "</td>\n",
       "<td>\n",
       "\"Absent\"\n",
       "</td>\n",
       "<td>\n",
       "\"AV\"\n",
       "</td>\n",
       "<td>\n",
       "4000\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "[\"TV\"]\n",
       "</td>\n",
       "<td>\n",
       "\"TV\"\n",
       "</td>\n",
       "<td>\n",
       "\"Abnormal\"\n",
       "</td>\n",
       "<td>\n",
       "\"Child\"\n",
       "</td>\n",
       "<td>\n",
       "\"Male\"\n",
       "</td>\n",
       "<td>\n",
       "\"98.0\"\n",
       "</td>\n",
       "<td>\n",
       "\"15.9\"\n",
       "</td>\n",
       "<td>\n",
       "\"False\"\n",
       "</td>\n",
       "<td>\n",
       "\"Holosystolic\"\n",
       "</td>\n",
       "<td>\n",
       "\"Plateau\"\n",
       "</td>\n",
       "<td>\n",
       "\"Low\"\n",
       "</td>\n",
       "<td>\n",
       "\"I/VI\"\n",
       "</td>\n",
       "<td>\n",
       "\"Blowing\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"CC2015\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "13918\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_PV.wav\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_PV.tsv\"\n",
       "</td>\n",
       "<td>\n",
       "\"Absent\"\n",
       "</td>\n",
       "<td>\n",
       "\"PV\"\n",
       "</td>\n",
       "<td>\n",
       "4000\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "[\"TV\"]\n",
       "</td>\n",
       "<td>\n",
       "\"TV\"\n",
       "</td>\n",
       "<td>\n",
       "\"Abnormal\"\n",
       "</td>\n",
       "<td>\n",
       "\"Child\"\n",
       "</td>\n",
       "<td>\n",
       "\"Male\"\n",
       "</td>\n",
       "<td>\n",
       "\"98.0\"\n",
       "</td>\n",
       "<td>\n",
       "\"15.9\"\n",
       "</td>\n",
       "<td>\n",
       "\"False\"\n",
       "</td>\n",
       "<td>\n",
       "\"Holosystolic\"\n",
       "</td>\n",
       "<td>\n",
       "\"Plateau\"\n",
       "</td>\n",
       "<td>\n",
       "\"Low\"\n",
       "</td>\n",
       "<td>\n",
       "\"I/VI\"\n",
       "</td>\n",
       "<td>\n",
       "\"Blowing\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"CC2015\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "13918\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_TV.wav\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_TV.tsv\"\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"TV\"\n",
       "</td>\n",
       "<td>\n",
       "4000\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "[\"TV\"]\n",
       "</td>\n",
       "<td>\n",
       "\"TV\"\n",
       "</td>\n",
       "<td>\n",
       "\"Abnormal\"\n",
       "</td>\n",
       "<td>\n",
       "\"Child\"\n",
       "</td>\n",
       "<td>\n",
       "\"Male\"\n",
       "</td>\n",
       "<td>\n",
       "\"98.0\"\n",
       "</td>\n",
       "<td>\n",
       "\"15.9\"\n",
       "</td>\n",
       "<td>\n",
       "\"False\"\n",
       "</td>\n",
       "<td>\n",
       "\"Holosystolic\"\n",
       "</td>\n",
       "<td>\n",
       "\"Plateau\"\n",
       "</td>\n",
       "<td>\n",
       "\"Low\"\n",
       "</td>\n",
       "<td>\n",
       "\"I/VI\"\n",
       "</td>\n",
       "<td>\n",
       "\"Blowing\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"CC2015\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "13918\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_MV.wav\"\n",
       "</td>\n",
       "<td>\n",
       "\"13918_MV.tsv\"\n",
       "</td>\n",
       "<td>\n",
       "\"Absent\"\n",
       "</td>\n",
       "<td>\n",
       "\"MV\"\n",
       "</td>\n",
       "<td>\n",
       "4000\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "[\"TV\"]\n",
       "</td>\n",
       "<td>\n",
       "\"TV\"\n",
       "</td>\n",
       "<td>\n",
       "\"Abnormal\"\n",
       "</td>\n",
       "<td>\n",
       "\"Child\"\n",
       "</td>\n",
       "<td>\n",
       "\"Male\"\n",
       "</td>\n",
       "<td>\n",
       "\"98.0\"\n",
       "</td>\n",
       "<td>\n",
       "\"15.9\"\n",
       "</td>\n",
       "<td>\n",
       "\"False\"\n",
       "</td>\n",
       "<td>\n",
       "\"Holosystolic\"\n",
       "</td>\n",
       "<td>\n",
       "\"Plateau\"\n",
       "</td>\n",
       "<td>\n",
       "\"Low\"\n",
       "</td>\n",
       "<td>\n",
       "\"I/VI\"\n",
       "</td>\n",
       "<td>\n",
       "\"Blowing\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"CC2015\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "14241\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"14241_AV.wav\"\n",
       "</td>\n",
       "<td>\n",
       "\"14241_AV.tsv\"\n",
       "</td>\n",
       "<td>\n",
       "\"Present\"\n",
       "</td>\n",
       "<td>\n",
       "\"AV\"\n",
       "</td>\n",
       "<td>\n",
       "4000\n",
       "</td>\n",
       "<td>\n",
       "4\n",
       "</td>\n",
       "<td>\n",
       "[\"AV\", \"MV\", ... \"TV\"]\n",
       "</td>\n",
       "<td>\n",
       "\"PV\"\n",
       "</td>\n",
       "<td>\n",
       "\"Abnormal\"\n",
       "</td>\n",
       "<td>\n",
       "\"Child\"\n",
       "</td>\n",
       "<td>\n",
       "\"Male\"\n",
       "</td>\n",
       "<td>\n",
       "\"87.0\"\n",
       "</td>\n",
       "<td>\n",
       "\"11.2\"\n",
       "</td>\n",
       "<td>\n",
       "\"False\"\n",
       "</td>\n",
       "<td>\n",
       "\"Early-systolic...\n",
       "</td>\n",
       "<td>\n",
       "\"Plateau\"\n",
       "</td>\n",
       "<td>\n",
       "\"Low\"\n",
       "</td>\n",
       "<td>\n",
       "\"II/VI\"\n",
       "</td>\n",
       "<td>\n",
       "\"Harsh\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "<td>\n",
       "\"CC2015\"\n",
       "</td>\n",
       "<td>\n",
       "\"nan\"\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (5, 28)\n",
       "┌──────────┬────────────┬──────────┬────────────┬─────┬────────────┬────────────┬────────┬────────────┐\n",
       "│ patient_ ┆ murmur_in_ ┆ audio_fi ┆ annotation ┆ ... ┆ dia_mur_gr ┆ dia_mur_qu ┆ campai ┆ additional │\n",
       "│ id       ┆ patient    ┆ le       ┆ _file      ┆     ┆ ading      ┆ ality      ┆ gn     ┆ _id        │\n",
       "│ ---      ┆ ---        ┆ ---      ┆ ---        ┆     ┆ ---        ┆ ---        ┆ ---    ┆ ---        │\n",
       "│ i64      ┆ str        ┆ str      ┆ str        ┆     ┆ str        ┆ str        ┆ str    ┆ str        │\n",
       "╞══════════╪════════════╪══════════╪════════════╪═════╪════════════╪════════════╪════════╪════════════╡\n",
       "│ 13918    ┆ Present    ┆ 13918_AV ┆ 13918_AV.t ┆ ... ┆ nan        ┆ nan        ┆ CC2015 ┆ nan        │\n",
       "│          ┆            ┆ .wav     ┆ sv         ┆     ┆            ┆            ┆        ┆            │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 13918    ┆ Present    ┆ 13918_PV ┆ 13918_PV.t ┆ ... ┆ nan        ┆ nan        ┆ CC2015 ┆ nan        │\n",
       "│          ┆            ┆ .wav     ┆ sv         ┆     ┆            ┆            ┆        ┆            │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 13918    ┆ Present    ┆ 13918_TV ┆ 13918_TV.t ┆ ... ┆ nan        ┆ nan        ┆ CC2015 ┆ nan        │\n",
       "│          ┆            ┆ .wav     ┆ sv         ┆     ┆            ┆            ┆        ┆            │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 13918    ┆ Present    ┆ 13918_MV ┆ 13918_MV.t ┆ ... ┆ nan        ┆ nan        ┆ CC2015 ┆ nan        │\n",
       "│          ┆            ┆ .wav     ┆ sv         ┆     ┆            ┆            ┆        ┆            │\n",
       "├╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌┼╌╌╌╌╌╌╌╌╌╌╌╌┤\n",
       "│ 14241    ┆ Present    ┆ 14241_AV ┆ 14241_AV.t ┆ ... ┆ nan        ┆ nan        ┆ CC2015 ┆ nan        │\n",
       "│          ┆            ┆ .wav     ┆ sv         ┆     ┆            ┆            ┆        ┆            │\n",
       "└──────────┴────────────┴──────────┴────────────┴─────┴────────────┴────────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"data/raw_training/training_data/\"\n",
    "df = loadTrainingData(data_dir)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin executing function...\n",
      "Finished executing function...\n",
      "Time to execute function (milliseconds): 0.04506111145019531\n",
      "\n",
      "\n",
      "Begin executing function...\n",
      "Finished executing function...\n",
      "Time to execute function (milliseconds): 0.07987022399902344\n",
      "\n",
      "\n",
      "Begin executing function...\n",
      "Finished executing function...\n",
      "Time to execute function (milliseconds): 0.0019073486328125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([['0', '0.242', '0'],\n",
       "  ['0.242', '0.400176', '1'],\n",
       "  ['0.400176', '0.497088', '2'],\n",
       "  ['0.497088', '0.620176', '3'],\n",
       "  ['0.620176', '0.780176', '4'],\n",
       "  ['0.780176', '0.920176', '1'],\n",
       "  ['0.920176', '1.060176', '2'],\n",
       "  ['1.060176', '1.200176', '3'],\n",
       "  ['1.200176', '1.340176', '4'],\n",
       "  ['1.340176', '1.460176', '1'],\n",
       "  ['1.460176', '1.600176', '2'],\n",
       "  ['1.600176', '1.720176', '3'],\n",
       "  ['1.720176', '1.880176', '4'],\n",
       "  ['1.880176', '1.980176', '1'],\n",
       "  ['1.980176', '2.120176', '2'],\n",
       "  ['2.120176', '2.220176', '3'],\n",
       "  ['2.220176', '2.380176', '4'],\n",
       "  ['2.380176', '2.540176', '1'],\n",
       "  ['2.540176', '2.640176', '2'],\n",
       "  ['2.640176', '2.760176', '3'],\n",
       "  ['2.760176', '2.900176', '4'],\n",
       "  ['2.900176', '3.020176', '1'],\n",
       "  ['3.020176', '3.160176', '2'],\n",
       "  ['3.160176', '3.280176', '3'],\n",
       "  ['3.280176', '3.440176', '4'],\n",
       "  ['3.440176', '3.560176', '1'],\n",
       "  ['3.560176', '3.700176', '2'],\n",
       "  ['3.700176', '3.840176', '3'],\n",
       "  ['3.840176', '4.040176', '4'],\n",
       "  ['4.040176', '4.180176', '1'],\n",
       "  ['4.180176', '4.320176', '2'],\n",
       "  ['4.320176', '4.440176', '3'],\n",
       "  ['4.440176', '4.600176', '4'],\n",
       "  ['4.600176', '4.700176', '1'],\n",
       "  ['4.700176', '4.820176', '2'],\n",
       "  ['4.820176', '4.940176', '3'],\n",
       "  ['4.940176', '5.100176', '4'],\n",
       "  ['5.100176', '5.260176', '1'],\n",
       "  ['5.260176', '5.380176', '2'],\n",
       "  ['5.380176', '5.500176', '3'],\n",
       "  ['5.500176', '5.660176', '4'],\n",
       "  ['5.660176', '5.820176', '1'],\n",
       "  ['5.820176', '5.980176', '2'],\n",
       "  ['5.980176', '6.100176', '3'],\n",
       "  ['6.100176', '6.280176', '4'],\n",
       "  ['6.280176', '6.380176', '1'],\n",
       "  ['6.380176', '6.520176', '2'],\n",
       "  ['6.520176', '6.620176', '3'],\n",
       "  ['6.620176', '6.834382', '4'],\n",
       "  ['6.834382', '6.946309', '1'],\n",
       "  ['6.946309', '7.100176', '2'],\n",
       "  ['7.100176', '7.200176', '3'],\n",
       "  ['7.200176', '7.380176', '4'],\n",
       "  ['7.380176', '7.500176', '1'],\n",
       "  ['7.500176', '7.660176', '2'],\n",
       "  ['7.660176', '7.780176', '3'],\n",
       "  ['7.780176', '7.944103', '4'],\n",
       "  ['7.944103', '8.040176', '1'],\n",
       "  ['8.040176', '8.180176', '2'],\n",
       "  ['8.180176', '8.300176', '3'],\n",
       "  ['8.300176', '8.500176', '4'],\n",
       "  ['8.500176', '8.620176', '1'],\n",
       "  ['8.620176', '8.780176', '2'],\n",
       "  ['8.780176', '8.900176', '3'],\n",
       "  ['8.900176', '9.100176', '4'],\n",
       "  ['9.100176', '9.220176', '1'],\n",
       "  ['9.220176', '9.380176', '2'],\n",
       "  ['9.380176', '9.460176', '3'],\n",
       "  ['9.460176', '9.720176', '4'],\n",
       "  ['9.720176', '9.813882', '1'],\n",
       "  ['9.813882', '23.6', '0']],\n",
       " [[0.242, 0.780176],\n",
       "  [0.780176, 1.340176],\n",
       "  [1.340176, 1.880176],\n",
       "  [1.880176, 2.380176],\n",
       "  [2.380176, 2.900176],\n",
       "  [2.900176, 3.440176],\n",
       "  [3.440176, 4.040176],\n",
       "  [4.040176, 4.600176],\n",
       "  [4.600176, 5.100176],\n",
       "  [5.100176, 5.660176],\n",
       "  [5.660176, 6.280176],\n",
       "  [6.280176, 6.834382],\n",
       "  [6.834382, 7.380176],\n",
       "  [7.380176, 7.944103],\n",
       "  [7.944103, 8.500176],\n",
       "  [8.500176, 9.100176],\n",
       "  [9.100176, 9.720176]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data_dir+'2530_AV.tsv'\n",
    "with open(example, 'r') as f:\n",
    "    file = [line.strip().split() for line in f]\n",
    "\n",
    "def readAnnotationFile(file_path, file):\n",
    "\n",
    "    # with open(file_path, 'r') as f:\n",
    "    #     file = [line.strip().split() for line in f]\n",
    "\n",
    "    segments = []\n",
    "    line = 0\n",
    "    while line<len(file)-3:\n",
    "        for i in range(4):\n",
    "            if int(file[line+i][2])!=1+i:\n",
    "                line += 1\n",
    "                break\n",
    "        else:\n",
    "            segments.append([float(file[line][0]), float(file[line+3][1])])\n",
    "            line += 4\n",
    "\n",
    "    return file, segments\n",
    "\n",
    "def readAnnotationFileV2(file_path, file):\n",
    "\n",
    "    # with open(file_path, 'r') as f:\n",
    "    #     file = [line.strip().split() for line in f]\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    line = 0\n",
    "    while line<len(file)-3:\n",
    "        if (int(file[line][2]), int(file[line+1][2]), int(file[line+2][2]), int(file[line+3][2])) == (1, 2, 3, 4):\n",
    "            segments.append([float(file[line][0]), float(file[line+3][1])])\n",
    "        line += 1\n",
    "\n",
    "    return file, segments\n",
    "\n",
    "def readAnnotationFileV3(file_path, file):\n",
    "\n",
    "    # with open(file_path, 'r') as f:\n",
    "    #     file = [line.strip().split() for line in f]\n",
    "\n",
    "    segments = []\n",
    "    # for line in file:\n",
    "    #     if line\n",
    "\n",
    "    return file, segments\n",
    "\n",
    "x = stopwatch(readAnnotationFile, example, file)\n",
    "print('\\n')\n",
    "y = stopwatch(readAnnotationFileV2, example, file)\n",
    "print('\\n')\n",
    "y = stopwatch(readAnnotationFileV3, example, file)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydoc import cli\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import helpers.audio_tools as adt\n",
    "import helpers.lut as lut\n",
    "import tqdm\n",
    "\n",
    "def __getCacheDir():\n",
    "    return 'cache'\n",
    "\n",
    "def loadTrainingData(data_dir, encode_data=False):\n",
    "    #file to store ingested data, inside cache_dir directory\n",
    "    cache_dir = __getCacheDir()\n",
    "    cache_file = 'ingested_data.json'\n",
    "    \n",
    "    #check if data has already been ingested and stored in cache_file\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    desired_audio_files = [x for x in os.listdir(data_dir) if x.endswith('.wav')]\n",
    "    data_is_saved = __checkCachedDataframe(desired_audio_files, cache_dir, cache_file)\n",
    "    \n",
    "    #load df from save file if it exists, otherwise generate df from raw data\n",
    "    if data_is_saved:\n",
    "        print('loading data from save file: ', cache_dir + '/' + cache_file)\n",
    "        df = pl.read_json(cache_dir + '/' + cache_file)\n",
    "    else:\n",
    "        print(\"loading raw data from \", data_dir)\n",
    "        nested_data = ['audio_file', 'annotation_file', 'recording_location']\n",
    "        df = (\n",
    "            __ingest_data(data_dir)\n",
    "            .explode(nested_data)           #explode df so that each audio file and its corresponding recording location is on its own line\n",
    "            .pipe(__getMurmurInRecording)   #get murmur_in_recording (whether a murmur is present in the corresponding recording)\n",
    "            .pipe(reorderCols)\n",
    "        )\n",
    "        # #save df to file. Future calls to loadData will load the df from this file\n",
    "        # df.write_json(cache_dir + '/' + cache_file)\n",
    "\n",
    "    if encode_data:\n",
    "        df = encodeData(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def getSpectrogram(df, data_dir):\n",
    "\n",
    "    #check if df already has a spectrogram column\n",
    "    if 'spectrogram' in df.columns:\n",
    "        return df\n",
    "\n",
    "    spectro_dir = __getCacheDir() + '/spectrograms'\n",
    "    os.makedirs(spectro_dir, exist_ok=True)\n",
    "\n",
    "    #check if spectrograms have already been created and stored in cache\n",
    "    desired_spectros = df.get_column('audio_file').apply(lambda x: x.replace('.wav', '.npy')).to_list()\n",
    "    spectros_are_saved = __checkCachedSpectros(desired_spectros, spectro_dir)\n",
    "\n",
    "    if spectros_are_saved:\n",
    "        length = df.height\n",
    "        progress = tqdm.tqdm(total=length, desc=\"Loading spectrograms from cache\")\n",
    "        out = df.with_column(\n",
    "            pl.col('audio_file').str.replace('.wav', '.npy')\n",
    "            .apply(lambda x: __function_with_logUpdater(progress, np.load(spectro_dir + '/' + x)))\n",
    "            .alias('spectrogram')\n",
    "        )\n",
    "        progress.close()\n",
    "    else:\n",
    "        length = df.height * 2\n",
    "        progress = tqdm.tqdm(total=length, desc=\"Generating spectrograms\")\n",
    "        out = df.with_column(\n",
    "            pl.col('audio_file')\n",
    "            .apply(lambda x: __function_with_logUpdater(progress, __file_to_spectro(x, path=data_dir, output_folder=spectro_dir)))\n",
    "            .apply(lambda x: __function_with_logUpdater(progress, np.load(spectro_dir + '/' + x)))\n",
    "            .alias('spectrogram')\n",
    "        )\n",
    "        progress.close()\n",
    "    \n",
    "    out = reorderCols(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def encodeData(data):\n",
    "    #assume no duplicate column names\n",
    "\n",
    "    #check if data is a polars dataframe\n",
    "    if not isinstance(data, pl.internals.frame.DataFrame):\n",
    "        raise Exception('data is of unsupported type \"{}\". Supported types include polars.internals.frame.DataFrame'.format(data.type()))\n",
    "\n",
    "    cipher = lut.getCipher()\n",
    "    data_columns = data.columns\n",
    "    numeric_data = [x for x in ['patient_id', 'total_locations', 'sampling_frequency', 'height', 'weight', 'additional_id'] if x in data_columns]\n",
    "    cipher_friendly_data = [x for x in cipher.keys() if x in data_columns and x!='murmur_locations']\n",
    "    unencoded_data = [x for x in data_columns if x not in (*numeric_data, *cipher_friendly_data, 'murmur_locations')]\n",
    "\n",
    "    out = data.select([\n",
    "        #cast numeric data to float type\n",
    "        pl.col(numeric_data)\n",
    "        .cast(pl.datatypes.Float64),\n",
    "\n",
    "        #in murmur_locations: encode each element of each list in column using cipher\n",
    "        pl.col('murmur_locations').arr.eval(pl.element().apply(lambda x: cipher['murmur_locations'][x])),\n",
    "\n",
    "        #encode cipher friendly data\n",
    "        pl.col(cipher_friendly_data)\n",
    "        .map(lambda x: __applyCipher(x, cipher)),\n",
    "\n",
    "        pl.col(unencoded_data)\n",
    "    ])\n",
    "\n",
    "    out = reorderCols(out)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def reorderCols(data):\n",
    "    #assume no duplicate column names in data\n",
    "    all_cols = data.columns\n",
    "\n",
    "    #desired order of columns\n",
    "    ordered_cols = [\n",
    "        'patient_id',           \n",
    "        'murmur_in_patient',               \n",
    "        'audio_file', \n",
    "        'annotation_file',\n",
    "        'spectrogram',\n",
    "        'mfcc',\n",
    "        'murmur_in_recording',         \n",
    "        'recording_location',  \n",
    "        'sampling_frequency',   \n",
    "        'total_locations',        \n",
    "        'murmur_locations',     \n",
    "        'most_audible_location',\n",
    "        'outcome',              \n",
    "        'age',                  \n",
    "        'sex',                  \n",
    "        'height',               \n",
    "        'weight',               \n",
    "        'pregnancy_status',     \n",
    "        'sys_mur_timing',       \n",
    "        'sys_mur_shape',        \n",
    "        'sys_mur_pitch',        \n",
    "        'sys_mur_grading',      \n",
    "        'sys_mur_quality',      \n",
    "        'dia_mur_timing',       \n",
    "        'dia_mur_shape',        \n",
    "        'dia_mur_pitch',        \n",
    "        'dia_mur_grading',      \n",
    "        'dia_mur_quality',      \n",
    "        'campaign',             \n",
    "        'additional_id',        \n",
    "    ]\n",
    "    ordered_cols = [x for x in ordered_cols if x in all_cols]\n",
    "\n",
    "    #remaining columns with no specified order\n",
    "    unordered_cols = sorted(set(all_cols).difference(set(ordered_cols)))\n",
    "\n",
    "    #columns are ordered as specified in order_cols.\n",
    "    #remaining columns are included afterwards.\n",
    "    out = data.select([*ordered_cols, *unordered_cols])\n",
    "    \n",
    "    return out\n",
    "    \n",
    "\n",
    "def splitDataframe(df, split_ratio=0.8):\n",
    "    total_size = df.height\n",
    "    head_size = round(split_ratio * total_size)\n",
    "    tail_size = total_size - head_size\n",
    "\n",
    "    df = df.sample(frac=1.0, shuffle=True)\n",
    "    head_df = df.head(head_size)\n",
    "    tail_df = df.tail(tail_size)\n",
    "    \n",
    "    return head_df, tail_df\n",
    "\n",
    "########################################################################\n",
    "#   PRIVATE FUNCTIONS\n",
    "########################################################################\n",
    "\n",
    "def __ingest_data(data_dir):\n",
    "\n",
    "    data = lut.getClinicalData()\n",
    "    clinical_iterables = lut.getClinicalIterables()\n",
    "\n",
    "    #loop through txt files in directory\n",
    "    total_txt_files = len([x for x in os.listdir(data_dir) if x.endswith('.txt')])\n",
    "    progress = tqdm.tqdm(total=total_txt_files, desc=\"Reading from .txt files in \"+data_dir)\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            # open text file\n",
    "            with open(data_dir + \"/\" + file, \"r\") as f:\n",
    "\n",
    "                # read first line\n",
    "                line = f.readline()\n",
    "                # split line into list\n",
    "                line = line.strip().split(\" \")\n",
    "                data['patient_id'].append(int(line[0]))\n",
    "                data['total_locations'].append(int(line[1]))\n",
    "                data['sampling_frequency'].append(int(line[2]))\n",
    "                \n",
    "                # loop through each line to check if it matches with an iterables or if it contains a wav file\n",
    "                audio_files = []\n",
    "                annotation_files = []\n",
    "                recording_locations = []\n",
    "                for line in f:\n",
    "                    # check if line contains .wav\n",
    "                    if \".wav\" in line:\n",
    "                        # split the line \n",
    "                        line_split = line.strip().split(\" \")\n",
    "                        audio_files.append(line_split[2]) \n",
    "                        annotation_files.append(line_split[3])\n",
    "                        recording_locations.append(line_split[0]) \n",
    "                    #loop through iterables to check if line matches with any of them\n",
    "                    else:\n",
    "                        for iterable in clinical_iterables:\n",
    "                            if line.startswith(clinical_iterables[iterable] + \":\"):\n",
    "                                # get the value of the iterable\n",
    "                                value = line.split(': ', 1)[1].strip()\n",
    "                                # add the value to the data\n",
    "                                data[iterable].append(value)\n",
    "                                break\n",
    "\n",
    "                data['audio_file'].append(audio_files)\n",
    "                data['annotation_file'].append(annotation_files)\n",
    "                data['recording_location'].append(recording_locations)\n",
    "                progress.update(1)\n",
    "    progress.close()\n",
    "\n",
    "    #save data in polars Dataframe\n",
    "    df = pl.DataFrame(data)\n",
    "\n",
    "    #split each element in murmur_locations (type=str) into list\n",
    "    df = df.with_column(pl.col('murmur_locations').str.split(by='+'))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def __getMurmurInRecording(data):\n",
    "    out = data.with_column(\n",
    "        pl.when(pl.col('murmur_in_patient').is_in(['Absent', 'Unknown']))\n",
    "        .then(pl.col('murmur_in_patient'))\n",
    "        .when(pl.all([\n",
    "            pl.col('murmur_in_patient')=='Present',\n",
    "            pl.col('recording_location').is_in('murmur_locations')\n",
    "        ]))\n",
    "        .then('Present')\n",
    "        .otherwise('Absent')\n",
    "        .alias('murmur_in_recording')\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def __file_to_spectro(file, path=\"\", output_folder='', sr =4000):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    spectro = adt.wav_to_spectro(path + \"/\" + file, sr=sr)\n",
    "    spectro_file = file.replace('.wav', '.npy')\n",
    "    np.save(output_folder + '/' + spectro_file, spectro)\n",
    "\n",
    "    return spectro_file\n",
    "\n",
    "\n",
    "def __function_with_logUpdater(progress, func):\n",
    "    progress.update(1)\n",
    "    out = func\n",
    "    return out\n",
    "\n",
    "#assumes data_dir and cache_dir both exist\n",
    "def __checkCachedDataframe(desired_audio_files, cache_dir, save_file):            \n",
    "    #check if save file exists in cache_dir\n",
    "    if save_file not in os.listdir(cache_dir):\n",
    "        data_is_saved = False\n",
    "    else:\n",
    "        try:\n",
    "            #check if saved data matches the desired data\n",
    "            saved_data = pl.read_json(cache_dir + '/' + save_file)\n",
    "            saved_audio_files = saved_data.get_column('audio_file').to_list()\n",
    "            if set(saved_audio_files) == set(desired_audio_files):\n",
    "                data_is_saved = True\n",
    "            else:\n",
    "                data_is_saved = False\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                'An unexpected error occured while trying to check the cache file \\n' +\n",
    "                '\\'%s\\' in the cache directory \\'%s\\'\\n' % (save_file, cache_dir) +\n",
    "                ' (see below for error message). \\n\\n' +\n",
    "                'Troubleshooting:\\n' + \n",
    "                ' - make sure that the cache directory exists\\n' + \n",
    "                ' - try deleting cache file and running program again\\n'\n",
    "            )\n",
    "            raise\n",
    "    return data_is_saved\n",
    "\n",
    "#assumes cache_dir exists\n",
    "def __checkCachedSpectros(desired_spectros, spectro_dir):\n",
    "    saved_spectros = os.listdir(spectro_dir)\n",
    "    if set(desired_spectros).issubset(set(saved_spectros)):\n",
    "        spectros_are_saved = True\n",
    "    else:\n",
    "        spectros_are_saved = False\n",
    "    return spectros_are_saved\n",
    "\n",
    "    \n",
    "\n",
    "def __applyCipher(col, cipher):\n",
    "    col_name = col.name\n",
    "    out = col.apply(lambda x: cipher[col_name][x])\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
