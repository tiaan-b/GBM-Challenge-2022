{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import helpers.input_processor as ip\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset as tfds\n",
    "import tensorflow_io as tfio\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.python.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_to_tf(df):\n",
    "    #convert to tensorflow dataset\n",
    "    ds = df.select(pl.all().map(lambda s: s.to_numpy())).row(0)\n",
    "    ds = tfds.from_tensor_slices(ds)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #split into train and test sets\n",
    "# split_ratio = 0.8\n",
    "# total_size = df.height\n",
    "# train_size = round(split_ratio * total_size)\n",
    "# test_size = total_size - train_size\n",
    "\n",
    "# df = df.sample(frac=1.0, shuffle=True)  #shuffle rows in dataframe\n",
    "# train_df = df.head(train_size)\n",
    "# test_df = df.tail(test_size)\n",
    "\n",
    "# #convert train and test sets from polars dataframe to tensorflow dataset\n",
    "# train_ds = pl_to_tf(train_df)\n",
    "# test_ds = pl_to_tf(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andres tensorflow code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import math, random\n",
    "\n",
    "import helpers.input_processor as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = path to audio file\n",
    "# samp_rate = sample rate of the signal\n",
    "# duration = length of time (in seconds) to which the signal is resized\n",
    "# do_augmentation = whether to perform audio and image augmentation on the signal\n",
    "# n_freq_masks = number of frequency masks\n",
    "# n_time_masks = number of time masks\n",
    "# remaining keyword argument are passed to transforms.MelSpectrogram()\n",
    "def preprocessAudio(x, samp_rate=4000, duration=25, do_augmentation=True, n_freq_masks=1, n_time_masks=1, n_mels=128, n_fft=1024, hop_len=None):\n",
    "    # read and load audio file in .wav format\n",
    "    sig, sr = torchaudio.load(x)\n",
    "\n",
    "    # Check that audio is mono (has 1 audio channel)\n",
    "    num_channels = sig.shape[0]\n",
    "    if num_channels != 1:\n",
    "        raise Exception('The provided audio file \\'%s\\' has %s channels, when 1 was expected' % (x, num_channels))\n",
    "    \n",
    "    # resize sample, either by padding it with silence or truncating it\n",
    "    num_rows, sig_len = sig.shape\n",
    "    max_len = sr * duration\n",
    "    if (sig_len > max_len):\n",
    "        # Truncate the signal to the given length\n",
    "        sig = sig[:,:max_len]\n",
    "    elif (sig_len < max_len):\n",
    "        # Pad with zeroes at the beginning and end of the signal\n",
    "        pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "        pad_end_len = max_len - sig_len - pad_begin_len\n",
    "        pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "        pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "        sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "\n",
    "    # Audio Augmentation    --------\\\n",
    "    if do_augmentation == True:\n",
    "        # time shift signal to the left or right by a random percent of its original length (max 99%)\n",
    "        _, sig_len = sig.shape\n",
    "        max_shift = 0.99\n",
    "        sig = sig.roll(int(random.random() * max_shift * sig_len))\n",
    "    #-------------------------------/\n",
    "\n",
    "    # get Mel spectrogram\n",
    "    top_db = 80\n",
    "    melSpec = torchaudio.transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "    melSpec = torchaudio.transforms.AmplitudeToDB(top_db=top_db)(melSpec)\n",
    "\n",
    "    # Image Augmentation    --------\\\n",
    "    if do_augmentation == True:\n",
    "        # Apply time and frequency mask\n",
    "        max_mask_pct=0.1\n",
    "        n_steps = melSpec.shape[2]\n",
    "        mask_value = melSpec.mean()\n",
    "        for i in range(n_freq_masks):\n",
    "            melSpec = torchaudio.transforms.FrequencyMasking(max_mask_pct * n_mels)(melSpec, mask_value)\n",
    "        for i in range(n_time_masks):\n",
    "            melSpec = torchaudio.transforms.TimeMasking(max_mask_pct * n_steps)(melSpec, mask_value)\n",
    "    #-------------------------------/\n",
    "\n",
    "    out = melSpec.numpy()\n",
    "    e3, e2, e1 = out.shape\n",
    "    out = out.reshape(e2,e1)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataframe(df, split_ratio=0.8):\n",
    "    total_size = df.height\n",
    "    train_size = round(split_ratio * total_size)\n",
    "    test_size = total_size - train_size\n",
    "\n",
    "    df = df.sample(frac=1.0, shuffle=True)\n",
    "    trainSet = df.head(train_size)\n",
    "    testSet = df.tail(test_size)\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras, keras.utils\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    # data is represented as a sequence of batches\n",
    "    def __init__(self, audioPaths, labels, preProcessor, batchSize = 32, shuffle=True):\n",
    "        self.audioPaths = audioPaths\n",
    "        self.labels = labels\n",
    "        self.preProcessor = preProcessor\n",
    "        self.batchSize = batchSize\n",
    "        self.shuffle = shuffle\n",
    "        self.classes = np.unique(self.labels)\n",
    "        self.numClasses = len(self.classes)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Get total number of batches\n",
    "        return int(np.floor(len(self.audioPaths) / self.batchSize))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get the batch at position 'index'\n",
    "        batch = self.batches[index]\n",
    "        # Apply preprocessing function to audio file paths and get the labels\n",
    "        X = np.array([self.preProcessor(self.audioPaths[x]) for x in batch])\n",
    "        # Y = keras.utils.to_categorical([self.labels[x] for x in batch], num_classes=self.numClasses)\n",
    "        Y = np.array([self.labels[x] for x in batch])\n",
    "        return X, Y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Get array of indices used to access data\n",
    "        dataIndices = np.arange(len(self)*self.batchSize)\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(dataIndices)\n",
    "        # Reshape into an array of batches, where each batch is an array of indices used to access data\n",
    "        self.batches = np.reshape(dataIndices, (len(self), self.batchSize))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from save file:  cache/ingested_data.json\n"
     ]
    }
   ],
   "source": [
    "#load data from dataframe\n",
    "data_dir = \"data/raw_training/training_data/\"\n",
    "target_label = 'murmur_in_recording'\n",
    "df = (\n",
    "    ip.loadTrainingData(data_dir)\n",
    "    .filter(pl.col(target_label) != 'Unknown')\n",
    "    .pipe(ip.encodeData)\n",
    "    .select([\n",
    "        pl.col('audio_file').apply(lambda x: os.path.join(data_dir, x)),\n",
    "        pl.col(target_label)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples:        998\n",
      "Positive Samples:     499\n",
      "Negative Samples:     499\n",
      "Percent Positive Samples:     0.5\n"
     ]
    }
   ],
   "source": [
    "# #balance the data so that there is an equal number of murmur positive and murmur negative samples\n",
    "# #do this by duplicating random rows of whichever group (pos or neg) is smaller\n",
    "# neg_df = df.filter(pl.col(target_label)==0.0)\n",
    "# pos_df = df.filter(pl.col(target_label)==1.0)\n",
    "# numNeg = neg_df.height\n",
    "# numPos = pos_df.height\n",
    "\n",
    "# while numNeg != numPos:\n",
    "#     if numNeg < numPos:\n",
    "#         df.vstack(neg_df.sample(n=min(numPos-numNeg, neg_df.height), shuffle=True), in_place=True)\n",
    "#     else: \n",
    "#         df.vstack(pos_df.sample(n=min(numNeg-numPos, pos_df.height), shuffle=True), in_place=True)\n",
    "#     numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "#     numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "\n",
    "# #reshuffle rows\n",
    "# df = df.sample(frac=1.0, shuffle=True)\n",
    "\n",
    "# #check number of positive and negative samples\n",
    "# numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "# numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "# print('Total Samples:       ', df.height)\n",
    "# print('Positive Samples:    ', numPos)\n",
    "# print('Negative Samples:    ', numNeg)\n",
    "# print('Percent Positive Samples:    ', numPos/(numPos+numNeg))\n",
    "\n",
    "\n",
    "# method 2:\n",
    "\n",
    "#balance the data so that there is an equal number of murmur positive and murmur negative samples\n",
    "#do this by duplicating random rows of whichever group (pos or neg) is smaller\n",
    "neg_df = df.filter(pl.col(target_label)==0.0)\n",
    "pos_df = df.filter(pl.col(target_label)==1.0)\n",
    "numNeg = neg_df.height\n",
    "numPos = pos_df.height\n",
    "\n",
    "if numNeg < numPos:\n",
    "    df = neg_df.vstack(pos_df.sample(n=numNeg))\n",
    "elif numPos < numNeg:\n",
    "    df = pos_df.vstack(neg_df.sample(n=numPos))\n",
    "else:\n",
    "    df = neg_df.vstack(pos_df)\n",
    "\n",
    "#reshuffle rows\n",
    "df = df.sample(frac=1.0, shuffle=True)\n",
    "\n",
    "#check number of positive and negative samples\n",
    "numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "print('Total Samples:       ', df.height)\n",
    "print('Positive Samples:    ', numPos)\n",
    "print('Negative Samples:    ', numNeg)\n",
    "print('Percent Positive Samples:    ', numPos/(numPos+numNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = splitDataframe(df)\n",
    "classes = df.get_column(target_label).unique().to_list()\n",
    "\n",
    "train_gen = DataGenerator(\n",
    "    audioPaths=train_df.get_column('audio_file').to_list(),\n",
    "    labels=train_df.get_column(target_label).to_list(),\n",
    "    preProcessor=preprocessAudio\n",
    ")\n",
    "test_gen = DataGenerator(\n",
    "    audioPaths=test_df.get_column('audio_file').to_list(),\n",
    "    labels=test_df.get_column(target_label).to_list(),\n",
    "    preProcessor=preprocessAudio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 128, 196)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_gen.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer, Flatten, Conv2D\n",
    "\n",
    "# a sequential model is a model that is made up of layers\n",
    "model = Sequential()\n",
    "# the input layer is the first layer in the model\n",
    "model.add(InputLayer(input_shape=(201, 201, 1)))\n",
    "# try modifying the number of nodes in the hidden layer to see how it affects the model\n",
    "# you can also try changing the activation function to see how it affects the model\n",
    "# adding more layers to the model may also help\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 20:32:52.005931: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2022-07-19 20:32:52.628877: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_6/flatten_4/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_492690/1405856346.py\", line 3, in <cell line: 3>\n      model.fit(train_gen)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/layers/reshaping/flatten.py\", line 98, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_6/flatten_4/Reshape'\nInput to reshape is a tensor with 24379392 values, but the requested shape requires a multiple of 1241888\n\t [[{{node sequential_6/flatten_4/Reshape}}]] [Op:__inference_train_function_5621]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#ch0000029vscode-remote?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbce\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m# we will keep track of the mean squared error using mse\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#ch0000029vscode-remote?line=1'>2</a>\u001b[0m \u001b[39m# hist = model.fit(train_gen, steps_per_epoch=np.ceil(float(len(train_labels)) / float(batch_size)), validation_data=test_gen, validation_steps=25, epochs=25) # changing the number of epochs may help the model!\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#ch0000029vscode-remote?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_gen)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_6/flatten_4/Reshape' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_492690/1405856346.py\", line 3, in <cell line: 3>\n      model.fit(train_gen)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 889, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 490, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/sequential.py\", line 374, in call\n      return super(Sequential, self).call(inputs, training=training, mask=mask)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 458, in call\n      return self._run_internal_graph(\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/functional.py\", line 596, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1014, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/tiaan/.local/lib/python3.8/site-packages/keras/layers/reshaping/flatten.py\", line 98, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_6/flatten_4/Reshape'\nInput to reshape is a tensor with 24379392 values, but the requested shape requires a multiple of 1241888\n\t [[{{node sequential_6/flatten_4/Reshape}}]] [Op:__inference_train_function_5621]"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='bce', metrics=['accuracy']) # we will keep track of the mean squared error using mse\n",
    "# hist = model.fit(train_gen, steps_per_epoch=np.ceil(float(len(train_labels)) / float(batch_size)), validation_data=test_gen, validation_steps=25, epochs=25) # changing the number of epochs may help the model!\n",
    "model.fit(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 196)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = os.path.join(data_dir, '85349_TV.wav')\n",
    "x = preprocessAudio(path)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
