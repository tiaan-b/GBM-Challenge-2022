{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polars'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mTF_GPU_THREAD_MODE\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgpu_private\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpolars\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpl\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252632d677075312e6f6b2e5562632e6361227d/home/tiaan/GBM-Challenge-2022/src/tensorflowInput.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlibrosa\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'polars'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "\n",
    "import polars as pl\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import helpers.input_processor as ip\n",
    "import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset as tfds\n",
    "import tensorflow_io as tfio\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.python.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from torchaudio import transforms\n",
    "from IPython.display import Audio\n",
    "import math, random\n",
    "\n",
    "import helpers.input_processor as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from packaging import version\n",
    "# pip install -U tensorboard_plugin_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def balanceData(df, method):\n",
    "    if method==1:\n",
    "        #balance the data so that there is an equal number of murmur positive and murmur negative samples\n",
    "        #do this by duplicating random rows of whichever group (pos or neg) is smaller\n",
    "        neg_df = df.filter(pl.col(target_label)==0.0)\n",
    "        pos_df = df.filter(pl.col(target_label)==1.0)\n",
    "        numNeg = neg_df.height\n",
    "        numPos = pos_df.height\n",
    "\n",
    "        while numNeg != numPos:\n",
    "            if numNeg < numPos:\n",
    "                df.vstack(neg_df.sample(n=min(numPos-numNeg, neg_df.height), shuffle=True), in_place=True)\n",
    "            else: \n",
    "                df.vstack(pos_df.sample(n=min(numNeg-numPos, pos_df.height), shuffle=True), in_place=True)\n",
    "            numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "            numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "\n",
    "        #reshuffle rows\n",
    "        df = df.sample(frac=1.0, shuffle=True)\n",
    "\n",
    "        #check number of positive and negative samples\n",
    "        numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "        numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "        print('Total Samples:       ', df.height)\n",
    "        print('Positive Samples:    ', numPos)\n",
    "        print('Negative Samples:    ', numNeg)\n",
    "        print('Percent Positive Samples:    ', numPos/(numPos+numNeg))\n",
    "    elif method==2:\n",
    "        #balance the data so that there is an equal number of murmur positive and murmur negative samples\n",
    "        #do this by filtering out rows of whichever group (pos or neg) is larger\n",
    "        neg_df = df.filter(pl.col(target_label)==0.0)\n",
    "        pos_df = df.filter(pl.col(target_label)==1.0)\n",
    "        numNeg = neg_df.height\n",
    "        numPos = pos_df.height\n",
    "\n",
    "        if numNeg < numPos:\n",
    "            df = neg_df.vstack(pos_df.sample(n=numNeg))\n",
    "        elif numPos < numNeg:\n",
    "            df = pos_df.vstack(neg_df.sample(n=numPos))\n",
    "        else:\n",
    "            df = neg_df.vstack(pos_df)\n",
    "\n",
    "        #reshuffle rows\n",
    "        df = df.sample(frac=1.0, shuffle=True)\n",
    "\n",
    "        #check number of positive and negative samples\n",
    "        numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "        numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "        print('Total Samples:       ', df.height)\n",
    "        print('Positive Samples:    ', numPos)\n",
    "        print('Negative Samples:    ', numNeg)\n",
    "        print('Percent Positive Samples:    ', numPos/(numPos+numNeg))\n",
    "    else:\n",
    "        raise Exception(f'Received unexpected input to \\'method\\' parameter: {method}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 50\n",
    "H = 128\n",
    "W = 313\n",
    "DEVICE = 'gpu'\n",
    "\n",
    "#load data from dataframe\n",
    "data_dir = \"data/raw_training/training_data/\"\n",
    "target_label = 'murmur_in_recording'\n",
    "df = (\n",
    "    ip.loadTrainingData(data_dir)\n",
    "    .filter(pl.col(target_label) != 'Unknown')\n",
    "    .pipe(ip.encodeData)\n",
    "    .select([\n",
    "        pl.col('audio_file').apply(lambda x: os.path.join(data_dir, x)),\n",
    "        pl.col(target_label)\n",
    "    ])\n",
    ")\n",
    "\n",
    "df = balanceData(df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from nvidia.dali import pipeline_def\n",
    "import nvidia.dali.fn as fn\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.plugin.tf as dali_tf\n",
    "\n",
    "#prefetch_queue_depth=2*BATCH_SIZE, num_threads=4\n",
    "@pipeline_def(device_id=0, batch_size=BATCH_SIZE)\n",
    "def pipe(audioPaths, labels, device, sr=4000, duration=20, augmentData=True):\n",
    "    # Load audio files\n",
    "    encoded, labelsOut = fn.readers.file(files=audioPaths, labels=labels)\n",
    "    audio, _ = fn.decoders.audio(encoded, sample_rate=sr)\n",
    "    if device=='gpu':\n",
    "        audio = audio.gpu()\n",
    "        labelsOut = labelsOut.gpu()\n",
    "\n",
    "    # Resize samples to uniform length, either by padding it with silence or truncating it\n",
    "    trimmedSize = duration*sr\n",
    "    audio = fn.slice(audio, 0, trimmedSize, axes=0, out_of_bounds_policy='pad')\n",
    "\n",
    "    # Time shift signal to the left or right by a random percent of its original length (max 99%)\n",
    "    #   NOT IMPLEMENTED \n",
    "    # breakpoint = fn.random.uniform(range=(0.,1.))\n",
    "    # head = fn.slice\n",
    "\n",
    "    # Get mel spectrogram\n",
    "    spec = fn.spectrogram(audio, device=device)\n",
    "    melSpec = fn.mel_filter_bank(spec, sample_rate=sr, nfilter=128)\n",
    "    melSpec = fn.to_decibels(melSpec, multiplier=10.0)\n",
    "\n",
    "    if augmentData==True:\n",
    "        # Apply time and frequency masking\n",
    "        # maskValue = fn.reductions.mean(melSpec, device='cpu')\n",
    "        maskValue = 0.\n",
    "        melSpec = fn.erase(melSpec, axes=0, fill_value=maskValue, anchor=fn.random.uniform(range=(0.,1.)), shape=fn.random.uniform(range=(0.,0.1)), normalized=True, device=device)\n",
    "        melSpec = fn.erase(melSpec, axes=1, fill_value=maskValue, anchor=fn.random.uniform(range=(0.,1.)), shape=fn.random.uniform(range=(0.,0.1)), normalized=True, device=device)\n",
    "        normalized = fn.normalize(melSpec)\n",
    "        samplesOut = normalized\n",
    "    else:\n",
    "        samplesOut = melSpec\n",
    "\n",
    "    return samplesOut, labelsOut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def splitDataframe(df, split_ratio=0.8):\n",
    "    total_size = df.height\n",
    "    head_size = round(split_ratio * total_size)\n",
    "    tail_size = total_size - head_size\n",
    "\n",
    "    df = df.sample(frac=1.0, shuffle=True)\n",
    "    head_df = df.head(head_size)\n",
    "    tail_df = df.tail(tail_size)\n",
    "    \n",
    "    return head_df, tail_df\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "train_df, test_df = splitDataframe(df, split_ratio=0.9)\n",
    "train_df, val_df = splitDataframe(train_df, split_ratio=0.8)\n",
    "numTrainBatches = math.ceil(train_df.height / BATCH_SIZE)\n",
    "numValBatches = math.ceil(val_df.height / BATCH_SIZE)\n",
    "numTestBatches = math.ceil(test_df.height / BATCH_SIZE)\n",
    "print(f'Training Set Size, Batches:      {train_df.height}, {numTrainBatches}')\n",
    "print(f'Validation Set Size, Batches:    {val_df.height}, {numValBatches}')\n",
    "print(f'Testing Set Size, Batches:       {test_df.height}, {numTestBatches}')\n",
    "\n",
    "# check that sets are unique\n",
    "for set1, set2 in [[train_df, val_df], [train_df, test_df], [val_df, test_df]]:\n",
    "    col1 = set1.get_column('audio_file')\n",
    "    col2 = set2.get_column('audio_file')\n",
    "    overlap = col1.is_in(col2)\n",
    "    if overlap.any():\n",
    "        print(col1.len(), col2.len())\n",
    "        print(overlap.value_counts())\n",
    "        raise Exception(\n",
    "            'Training, validation, and/or testing sets are not unique.' +\n",
    "            f' Number of overlaps: {col1.filter(overlap).len()}'\n",
    "        )\n",
    "\n",
    "with tf.device('/gpu:0' if DEVICE=='gpu' else '/cpu:0'):\n",
    "    # Define shapes and types of the outputs\n",
    "    shapes = ((BATCH_SIZE, H, W), (BATCH_SIZE))\n",
    "    dtypes = (tf.float32, tf.int32)\n",
    "\n",
    "    # Create pipelines\n",
    "    train_pipe = pipe(audioPaths=train_df.get_column('audio_file').to_list(),\n",
    "                    labels=train_df.get_column(target_label).to_list(),\n",
    "                    device=DEVICE)\n",
    "    val_pipe = pipe(audioPaths=val_df.get_column('audio_file').to_list(),\n",
    "                    labels=val_df.get_column(target_label).to_list(),\n",
    "                    device=DEVICE)            \n",
    "    test_pipe = pipe(audioPaths=test_df.get_column('audio_file').to_list(),\n",
    "                    labels=test_df.get_column(target_label).to_list(),\n",
    "                    device=DEVICE)\n",
    "\n",
    "    # Create datasets\n",
    "    kwargs = dict(batch_size=BATCH_SIZE,\n",
    "                  output_shapes=shapes,\n",
    "                  output_dtypes=dtypes,\n",
    "                  device_id=0,\n",
    "                  prefetch_queue_depth=4,\n",
    "                  num_threads=4,\n",
    "                  exec_separated=True)\n",
    "    train_set = dali_tf.DALIDataset(pipeline=train_pipe, **kwargs)\n",
    "    val_set = dali_tf.DALIDataset(pipeline=val_pipe, **kwargs)\n",
    "    test_set = dali_tf.DALIDataset(pipeline=test_pipe, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# train_pipe.build()\n",
    "# train_pipe.save_graph_to_dot_file('DALIgraph2.dot', use_colors=True, show_ids=False, show_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#keras script\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras import datasets, layers, models\n",
    "\n",
    "with tf.device('/gpu:0' if DEVICE=='gpu' else '/cpu:0'):\n",
    "    # Design model\n",
    "    input_shape = (H, W, 1) # 128,313,1\n",
    "    model = Sequential()\n",
    "\n",
    "    # Arcitecture\n",
    "    # model.add(layers.Conv2D(8, (3,3), activation='relu', input_shape=input_shape, padding='same'))\n",
    "    # model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    # model.add(layers.Conv2D(16, (5,5), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    # model.add(layers.Conv2D(32, (5,5), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    # model.add(layers.Conv2D(64, (5,5), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D(pool_size=(2,2), strides=2))\n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(128, activation='relu'))\n",
    "    # model.add(layers.Dense(64, activation='relu'))\n",
    "    # model.add(layers.Dense(32, activation='relu'))\n",
    "    # model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(layers.MaxPool2D((2,2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Conv2D(256, (3,3), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D((2,2)))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    # model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "    # model.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape))\n",
    "    # model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D((2,2)))\n",
    "    # model.add(layers.Dropout(0.2))\n",
    "    # model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    # model.add(layers.Conv2D(32, (3,3), activation='relu'))\n",
    "    # model.add(layers.MaxPool2D((2,2)))\n",
    "    # model.add(layers.Dropout(0.5))\n",
    "    # model.add(layers.Flatten())\n",
    "    # model.add(layers.Dense(64, activation='relu'))\n",
    "    # model.add(layers.Dropout(0.5))\n",
    "    # # model.add(layers.Dense(32, activation='relu'))\n",
    "    # model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='bce', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # # Create a TensorBoard callback\n",
    "    # logs = \"logs/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = logs, histogram_freq = 1, profile_batch = '10,15')\n",
    "\n",
    "    # Train model on dataset\n",
    "    history = model.fit(\n",
    "        x=train_set,\n",
    "        validation_data=val_set,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        steps_per_epoch=int(numTrainBatches*0.9),\n",
    "        validation_steps=int(numValBatches*0.9),\n",
    "        # callbacks=tboard_callback\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Adapted from Deep Learning with Python by Francois Chollet, 2018\n",
    "history_dict=history.history\n",
    "loss_values=history_dict['loss']\n",
    "acc_values=history_dict['accuracy']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "val_acc_values=history_dict['val_accuracy']\n",
    "epochs=range(1,NUM_EPOCHS+1)\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
    "ax1.plot(epochs,loss_values,'bo',label='Training Loss')\n",
    "ax1.plot(epochs,val_loss_values,'orange', label='Validation Loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax2.plot(epochs,acc_values,'bo', label='Training accuracy')\n",
    "ax2.plot(epochs,val_acc_values,'orange',label='Validation accuracy')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.evaluate(test_set, steps=numTestBatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train', color='red')\n",
    "plt.plot(history.history['val_loss'], label='test', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train', color='red')\n",
    "plt.plot(history.history['val_accuracy'], label='test', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Launch TensorBoard and navigate to the Profile tab to view performance profile\n",
    "%tensorboard --logdir=logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
