{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import helpers.input_processor as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from save file:  cache/ingested_data.json\n"
     ]
    }
   ],
   "source": [
    "#load data from dataframe\n",
    "data_dir = \"data/raw_training/training_data/\"\n",
    "target_label = 'murmur_in_recording'\n",
    "df = (\n",
    "    ip.loadTrainingData(data_dir)\n",
    "    .filter(pl.col(target_label) != 'Unknown')\n",
    "    .pipe(ip.encodeData)\n",
    "    .select([\n",
    "        pl.col('audio_file').apply(lambda x: os.path.join(data_dir, x)),\n",
    "        pl.col(target_label)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples:        5328\n",
      "Positive Samples:     2664\n",
      "Negative Samples:     2664\n",
      "Percent Positive Samples:     0.5\n"
     ]
    }
   ],
   "source": [
    "#balance the data so that there is an equal number of murmur positive and murmur negative samples\n",
    "#do this by duplicating random rows of whichever group (pos or neg) is smaller\n",
    "neg_df = df.filter(pl.col(target_label)==0.0)\n",
    "pos_df = df.filter(pl.col(target_label)==1.0)\n",
    "numNeg = neg_df.height\n",
    "numPos = pos_df.height\n",
    "\n",
    "while numNeg != numPos:\n",
    "    if numNeg < numPos:\n",
    "        df.vstack(neg_df.sample(n=min(numPos-numNeg, neg_df.height), shuffle=True), in_place=True)\n",
    "    else: \n",
    "        df.vstack(pos_df.sample(n=min(numNeg-numPos, pos_df.height), shuffle=True), in_place=True)\n",
    "    numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "    numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "\n",
    "#reshuffle rows\n",
    "df = df.sample(frac=1.0, shuffle=True)\n",
    "\n",
    "#check number of positive and negative samples\n",
    "numNeg = df.filter(pl.col(target_label)==0.0).height\n",
    "numPos = df.filter(pl.col(target_label)==1.0).height\n",
    "print('Total Samples:       ', df.height)\n",
    "print('Positive Samples:    ', numPos)\n",
    "print('Negative Samples:    ', numNeg)\n",
    "print('Percent Positive Samples:    ', numPos/(numPos+numNeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "# x = path to audio file\n",
    "# duration = length of time (in seconds) to which the signal is resized\n",
    "# sr = sample rate of the signal\n",
    "def preprocessAudio(x, duration, sr=4000):\n",
    "    #read and load audio file in .wav format\n",
    "    sig, samp_rate = librosa.load(x, sr=sr) #make sure that the correct sample rate is passed as a parameters. if unspecified, the function chooses some default value\n",
    "\n",
    "    #resize sample, either by padding it with silence or truncating it\n",
    "    sig = librosa.util.fix_length(sig, size=sr*duration)\n",
    "\n",
    "    #implement audio augmentation:  ------------\n",
    "    #time shift signal to the left or right by a random percent of its original length (max 99%)\n",
    "    sig_len = sig.shape[0]\n",
    "    max_shift = 0.99\n",
    "    sig = np.roll(sig, round(random.random() * max_shift * sig_len))\n",
    "    #-------------------------------------------\n",
    "\n",
    "    #get Mel spectrogram\n",
    "    melSpec = librosa.feature.melspectrogram(y=sig, sr=samp_rate)\n",
    "    melSpec = librosa.amplitude_to_db(melSpec)\n",
    "\n",
    "    #implement image augmentation   ------------\n",
    "    #-------------------------------------------\n",
    "    \n",
    "    return melSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, audioPaths, labels):\n",
    "        self.audioPaths = audioPaths\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        spec = preprocessAudio(self.audioPaths[idx])\n",
    "        label = self.labels[idx]\n",
    "        return spec, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(ds, split_ratio=0.8):\n",
    "    total_size = len(ds)\n",
    "    train_size = round(split_ratio * total_size)\n",
    "    test_size = total_size - train_size\n",
    "\n",
    "    trainSet, testSet = torch.utils.data.random_split(ds, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "    return trainSet, testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4262 1066\n"
     ]
    }
   ],
   "source": [
    "audioPaths = df.get_column('audio_file').to_list()\n",
    "labels = df.get_column(target_label).to_list()\n",
    "\n",
    "ds = AudioDataset(audioPaths, labels)\n",
    "trainset, testset = splitDataset(ds)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
